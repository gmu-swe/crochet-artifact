
\documentclass[12pt]{article}

\renewcommand\thesection{\Alph{section}}

\usepackage{url}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{soul}
\usepackage{xspace}
\usepackage[]{authblk}

% Monotype font with bold for listings
%\renewcommand{\ttdefault}{pcr}

\newcommand{\command}[1]{\colorbox{black}{\texttt{\color{white}#1}}}
\newcommand{\host}[1]{\colorbox{blue!20}{\texttt{\color{black}#1}}}
\newcommand{\vm}[1]{\colorbox{green!20}{\texttt{\color{black}#1}}}
\newcommand{\XXX}{\colorbox{red}{\bf\color{white}XXX}}
\newcommand{\sysname}{\textsc{Crochet}\xspace}
\newcommand{\papertitle}{\sysname: Checkpoint and Rollback via Lightweight Heap Traversal on Stock JVMs\xspace}

\title{\emph{\papertitle} \\ Artifact Guide}
\author{Jonathan Bell and Lu\'{i}s Pina \\ \texttt{[bellj,lpina2]@gmu.edu}}
\affil{George Mason University}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}

    This guide covers the artifact for the paper \papertitle.

    The artifact is composed of two Virtual Machines, which are provisioned by
    Vagrant: one (the primary artifact) contains the bulk of the evaluation on an Ubuntu 16.04 image,
    the other (which involves reproducing other author's prior results) contains a single experiment on a Centos/7 image.

    The guide describes how to (mostly automatically) reproduce all of tables in the paper,
    and provides information about how to match the pseudo-code with the
    prototype and how to extract the artifact from the VM to run it directly.
    The artifact also builds most of the code neeeded from source, which enables
    to use it to test modifications to \sysname with low effort. \sysname also includes a suite of integration tests, which can be inspected and modified to demonstrate different behaviors.

\end{abstract}

\section{Introduction}
\label{sec:first}

This is the guide for the artifact for the paper \papertitle.  This artifact consists
of two VMs which are set-up and provisioned using
Vagrant.\footnote{\url{https://www.vagrantup.com/}}  You should install Vagrant
and Virtualbox\footnote{\url{https://www.virtualbox.org/wiki/VirtualBox}} in
your system.  We tested this artifact with Vagrant version 2.0.1 and Virtualbox
version 5.2.4 on GNU/Linux version 4.14.13-1-ARCH (Arch Linux), but of course, expect it to work fine on any host OS.

The sections on this paper are \emph{named} \ref{sec:first} through
\ref{sec:last} to avoid any confusion with the sections on the paper, which are
\emph{numbered} 1 through 8.

Section~\ref{sec:structure} describes the structure of the artifact,
Section~\ref{sec:provision} describes how to provision each VM,
Section~\ref{sec:run} describes how to run each experiment,
Section~\ref{sec:tables} describes how to generate the tables on the paper from
the results, Section~\ref{sec:algorithm} describes how to match the algorithm in
Listings 1 and 2 with \sysname's code, and Section~\ref{sec:extract} explains how to
extract the artifact from its VM to run the experiments directly.

To \emph{``kick-the-tires''}, we recommend following:
Section~\ref{sec:structure}, Section~\ref{sec:provision},
Section~\ref{sec:quickrun}, and Section~\ref{sec:tables}.

The timings are reported for two machines.  The \emph{user machine} is equipped
with one Intel(R) Core(TM) i7-7700HQ CPU (4 physical cores, 8 logical) and 32GB
RAM, running GNU/Linux version 4.14.13-1-ARCH (Arch Linux).  The \emph{test
machine} is equipped with two Intel(R) Xeon(R) CPU E5-2650L v3 CPUs (12 physical
cores per CPU, 24 logical per CPU, 48 total) and 128GB RAM, running GNU/Linux
version 4.4.0-116-generic (Ubuntu 16.04.4 LTS).

In terms of notation, commands to be executed on the VM look \command{like
this}, files on the host machine look \host{like this}, and files on the VM look
\vm{like this}.

\section{Structure of this artifact}
\label{sec:structure}

\subsection{Main VM}
\label{sec:main}

The first VM is the Main VM that runs all the experiments except Table~4 on
Section~5.3 on the paper.  It uses Ubuntu 16.04 LTS as the underlying operating
system, and you can find it in directory \XXX.  Its structure is as follows:

\begin{description}

    \item[Vagrantfile] File that describes how Vagrant should provision the VM.
        Parameter \texttt{config.vm.provision}, at the end of the file,
        describes how to provision the artifact VM by running shell scripts
        listed below on this document.  Please customize the following
        parameters:

        \begin{description}

            \item[vm.memory] Memory that the VM will have.  We recommend at least 8G (8192MB).

            \item[vm.cpus] Number of CPUs available to the VM.  We recomment at least 2, more is better.

        \end{description}

    \item[downloads] The artifact requires some files to be downloaded from the
        internet and saved here.  We already populated this directory for your
        convenience.  File \host{scripts/downloads.sh} should be able to
        re-download them if needed.

        \begin{itemize}

            \item Oracle HotSpot JDK7

            \item Oracle HotSpot JDK8

            \item DaCapo 9.12 jar file

        \end{itemize}

    \item[scripts]  Several scripts and utilities used throughout the VM.  File
        \host{scripts/path.sh} is of particular interest as it sets the
        environment used throughout the artifact.  Ensure that variable
        \texttt{GLOBAL\_JVM\_PARAMS} configures JVMs with a maximum heap size
        that fits in the memory you configured the artifact VM with, in file
        \host{Vagrantfile} with parameter \texttt{vb.memory}.  We recommend at
        least 4GB with: \texttt{GLOBAL\_JVM\_PARAMS="-Xmx4G"}

    \item[experiments]  Each experiment reported in the paper has a
        subdirectory with the scripts to run it and generate a table with its
        results:

        \begin{description}

            \item[microbenchmarks] Section~5.1

            \item[dacapo] Section~5.2

            \item[stmbench7] Section~5.3, Table~3

            \item[ftp] Section~6.1

            \item[dacapo-h2] Section~6.2

        \end{description}

    \item[results]  The artifact saves the raw results of each experiment in
        this directory, under a subdirectory structure similar to the
        experiments structure.

    \item[tables]  Similarly to the results, the artifact saves in this
        directory the tables generated from the raw results.

\end{description}

\subsection{XJ VM}
\label{sec:xj}

The second VM only runs the experiments for Table~4 in Section~5.2 of the paper.
It is necessary to use this separate VM for this experiment because the subject of comparison (XJ) requires many particular dependency versions to compile and run.

The structure of the VM is very similar to the Main VM, described in
Section~\ref{sec:main}.

\begin{description}

    \item[Vagrantfile] Similar file to the Main VM, please configure it as you
        did above.

    \item[downloads] The XJ VM requires the sources of the XJ JVM and the
        experiments it uses.  These files were kindly made available by the
        authors of XJ, and are saved here.

        \begin{itemize}

            \item openjdk.zip

            \item xj.zip

        \end{itemize}

        As for the Main VM, it also requires the JVMs used in testing:

        \begin{itemize}

            \item Oracle HotSpot JDK7

            \item Oracle HotSpot JDK8

        \end{itemize}

        Also, as for the Main VM, we already populated this folder with all the
        required files.

    \item[scripts]  Same as above, please configure it in a similar way.

    \item[patches]  Some patches required to build the required software on this VM.

    \item[experiments]  Only one experiment in this VM:

        \begin{description}

            \item[xj] Section~5.3, Table~4

        \end{description}

    \item[results]  Not used, moved to \vm{\$HOME/results}.  See
        Section~\ref{sec:sync} for the reasons behind this decision.


    \item[tables]  Not used, moved to folder \vm{\$HOME/tables}.  See
        Section~\ref{sec:sync} for the reasons behind this decision.

\end{description}

\subsection{Folder synchronization between host and VM}
\label{sec:sync}

Vagrant mounts the directory that contains file \host{Vagrantfile} under
\vm{/vagrant} inside the VM.

On the Main VM, these two directories are synchronized in both directions:
Writes from the host are visible inside the VM, and vice-versa.  Saving the
results and tables in \vm{/vagrant/results} and \vm{/vagrant/tables}
ensures that you can access them from the host on folders \host{results} and
\host{tables} without needing to start the VM.

Because of this synchronization, running some experiments from inside
\vm{/vagrant} will incur I/O overhead that skews results.  We recommend
running all experiments from \vm{\$HOME}.

On the XJ VM, the two folders are synchronized only in one direction:  On VM
startup, Vagrant overwrites the contents of \vm{/vagrant} with the contents
of the directory that contains file \host{Vagrantfile}.

For the results and tables not to be lost between VM cycling, they can be found
in folder \vm{\$HOME/results} and \vm{\$HOME/tables} inside the XJ VM.
Unfortunately, you have to copy them manually to the host machine (e.g., by
using \texttt{scp}).

\section{Provision the VM}
\label{sec:provision}

This section explains how to provision each VM. When each VM is provisioned for the first time, a moderately-sized base image will be downloaded from Vagrant's repository for each (containing the base OS image for Ubuntu/Centos), and then various dependencies (e.g. python, java) will be installed in that VM. Nothing is downloaded from any site that the author's have access to, and nothing is downloaded that is specific to this artifact.

\subsection{Main VM}

Once you have configured file \host{Vagrantfile} and have all required
downloaded files, as described in Section~\ref{sec:main}, simply run the command
\command{vagrant up} from the directory \XXX.  Provisioning the Main VM took around 10
minutes on the user machine.

While the provisioning script runs, you may see little output. On our user machine the script showed no output for several minutes while at this step:
\begin{verbatim}
	$ vagrant up
Bringing machine 'default' up with 'virtualbox' provider...
==> default: Importing base box 'ubuntu/xenial64'...
==> default: Matching MAC address for NAT networking...
==> default: Setting the name of the VM: CROCHET Artifact
==> default: Clearing any previously set network interfaces...
==> default: Preparing network interfaces based on configuration...
    default: Adapter 1: nat
==> default: Forwarding ports...
    default: 22 (guest) => 2222 (host) (adapter 1)
==> default: Running 'pre-boot' VM customizations...
==> default: Booting VM...
==> default: Waiting for machine to boot. This may take a few minutes...
    default: SSH address: 127.0.0.1:2222
    default: SSH username: ubuntu
    default: SSH auth method: password
\end{verbatim}

If you abort the provisioning and the vm is stuck in an inconsistent state, simply run \command{vagrant destroy} then \command{vagrant up} again --- it will eliminate all traces of the VM and redeploy it.

The full output from a successful completion of this step is included in this artifact in \command{sample\_output/C.1.txt}.

\subsection{XJ VM}

Similar to the Main VM, once you have performed all configuration, for instance in  \host{Vagrantfile}, as described in Section~\ref{sec:xj}, simply
run the command \command{vagrant up} from the directory \XXX.  This will download the base CentOS image from Vagrant and compile the artifact as needed. Provisioning the
XJ VM took around 30 minutes on the user machine.

\section{Run the experiments}
\label{sec:run}

To log-on to a provisioned VM, use the command \command{vagrant ssh}, executed from the directory containing the artifact that you would like to connct to.  If a provisioned
machine is not running (either is stopped or suspended), you can start it with
command \command{vagrant up}.  To stop a running VM, log-on and type \command{sudo
poweroff}.  To suspend a running vm, use command \command{vagrant suspend}. To remove all traces of a vm from your machine, use command \command{vagrant destroy}.

To run any experiment, you should log-on to the VM and type command
\command{source /vagrant/scripts/paths.sh} to set up the environment correctly.

Please note, for the Main VM, that folder \command{/vagrant} is the same folder
where you typed \command{vagrant up} on the host machine, and any changes between
these folders are synchronized.  As a result, results and tables generated
inside the VM are automatically available to the host machine.

Some experiments (e.g., DaCapo) write scratch results on the directory in which
they are launched from.  Therefore, to avoid directory synchronization overhead (where the OS will constantly try to sync these temporary files),
we recommend running the experiments from folder \host{\$HOME} on the
Main VM.

For the XJ VM, these two folders are only synchronized from the host to the VM
by copying the contents of the folder on the host at VM startup time.
Extracting the results requires other means (e.g., \command{scp}).

To stop a running experiment, interrupting the experiment script with
\texttt{CTRL+C} is not enough, as the current iteration will continue to execute
in the background.  You can stop it with command \command{killall -KILL java}.

All experiments run on the Main VM, except for experiments reported in Table~4.

\subsection{Quick run}
\label{sec:quickrun}

Quick runs are smaller versions of the regular experiment, ideal for the
\emph{kick-the-tires} phase of testing.  If these experiments complete
successfully, then the regular experiments should also do so.  In the following,
we describe how to run each quick experiment.

Note that quick experiments write their results in the same directory of the
regular experiments.  This is so that you can also test the scripts that
generate the tables from the data.  However, running a quick experiment will
overwrite any data left from the regular experiment.

\subsubsection{Main VM}

\begin{description}

    \item[microbenchmarks] Run command
        \command{/vagrant/experiments/micro/run-quick.py}.  This runs an
        experiment for each cell of Table 1 twice.  Running this set of
        experiments took around 30 minutes on the user machine.

        Once the experiment finishes, you can check that there are no errors
        ensuring that command \command{grep -Ri exception /vagrant/results/microbenchmark}
        does not print anything.

        Note that this quick run does not generate timed results, so the
        table generating scripts described in Section~\ref{sec:tables} will not
        work.  If you want to try those, set variable \texttt{GLOBAL\_TIMES} to
        2 in file \command{/vagrant/scripts/paths.sh}, reset the environment with
        command \command{source /vagrant/scripts/paths.sh} and do a paper run,
        described in Section~\ref{sec:paper-run} (doing a ``quick'' run will never be timed).

Sample output:
\begin{verbatim}
	ubuntu@crochet-artifact:~$ /vagrant/experiments/microbenchmarks/run-quick.py 
run  default no-check-no-sum-crochet 0 - 2018-04-21 14:55:08.343330
run  default no-check-sum-crochet 0 - 2018-04-21 15:01:40.703791
run  default check-sum-mapcloner 0 - 2018-04-21 15:08:40.625401
run  default check-sum-crochet 0 - 2018-04-21 15:08:43.140047
run  default check-sum-criu 0 - 2018-04-21 15:16:37.201023
run  default check-sum-cloner 0 - 2018-04-21 15:22:04.713291
run  default no-check-sum-native 0 - 2018-04-21 15:22:07.246505
run  default check-sum-serial 0 - 2018-04-21 15:22:08.662749
run  default no-check-no-sum-native 0 - 2018-04-21 15:22:12.861244
run  default check-no-sum-serial 0 - 2018-04-21 15:22:14.369322
run  default check-no-sum-crochet 0 - 2018-04-21 15:22:19.913677
\end{verbatim}
    \item[dacapo] Run command \command{/vagrant/experiments/dacapo/run-quick.py}.
        This runs an experiment for each cell of Table 2 twice.  Running this
        set of experiments took around 5 minutes on the user machine.

        Once the experiment finishes, you can check that there are no errors
        ensuring that command \command{grep -R FAIL /vagrant/results/dacapo} does not
        print anything.  Note that benchmark \texttt{tradesoap} may fail
        non-deterministically even for the native case, and is not included on
        the main results on Table 2; please ignore errors from this benchmark.

Sample output:
\begin{verbatim}
	$ /vagrant/experiments/dacapo/run-quick.py 
run  lusearch crochet-callback 0 - 2018-04-21 15:31:15.633116
run  lusearch crochet-callback 1 - 2018-04-21 15:31:20.224062
run  lusearch crochet 0 - 2018-04-21 15:31:24.570216
run  lusearch crochet 1 - 2018-04-21 15:31:27.768157
run  lusearch native 0 - 2018-04-21 15:31:31.117231
run  lusearch native 1 - 2018-04-21 15:31:32.089161
run  jython crochet-callback 0 - 2018-04-21 15:31:33.005707
run  jython crochet-callback 1 - 2018-04-21 15:31:49.908328
run  jython crochet 0 - 2018-04-21 15:32:05.451510
run  jython crochet 1 - 2018-04-21 15:32:20.242040
run  jython native 0 - 2018-04-21 15:32:35.466853
run  jython native 1 - 2018-04-21 15:32:44.132977
run  h2 crochet-callback 0 - 2018-04-21 15:32:52.475286
run  h2 crochet-callback 1 - 2018-04-21 15:33:01.596768
run  h2 crochet 0 - 2018-04-21 15:33:13.014452
run  h2 crochet 1 - 2018-04-21 15:33:22.597781
run  h2 native 0 - 2018-04-21 15:33:29.534477
run  h2 native 1 - 2018-04-21 15:33:33.513940
run  pmd crochet-callback 0 - 2018-04-21 15:33:37.649036
run  pmd crochet-callback 1 - 2018-04-21 15:33:41.359983
run  pmd crochet 0 - 2018-04-21 15:33:45.056416
run  pmd crochet 1 - 2018-04-21 15:33:49.126815
run  pmd native 0 - 2018-04-21 15:33:52.579549
run  pmd native 1 - 2018-04-21 15:33:53.097625
run  avrora crochet-callback 0 - 2018-04-21 15:33:53.624243
run  avrora crochet-callback 1 - 2018-04-21 15:33:59.290246
run  avrora crochet 0 - 2018-04-21 15:34:10.919440
run  avrora crochet 1 - 2018-04-21 15:34:16.627932
run  avrora native 0 - 2018-04-21 15:34:24.128653
run  avrora native 1 - 2018-04-21 15:34:28.556114
run  luindex crochet-callback 0 - 2018-04-21 15:34:32.484130
run  luindex crochet-callback 1 - 2018-04-21 15:34:35.303964
run  luindex crochet 0 - 2018-04-21 15:34:38.159890
run  luindex crochet 1 - 2018-04-21 15:34:41.208146
run  luindex native 0 - 2018-04-21 15:34:44.418504
run  luindex native 1 - 2018-04-21 15:34:44.946866
run  fop crochet-callback 0 - 2018-04-21 15:34:45.475395
run  fop crochet-callback 1 - 2018-04-21 15:34:50.860446
run  fop crochet 0 - 2018-04-21 15:34:55.952969
run  fop crochet 1 - 2018-04-21 15:35:00.410421
run  fop native 0 - 2018-04-21 15:35:05.310218
run  fop native 1 - 2018-04-21 15:35:06.654539
run  tomcat crochet-callback 0 - 2018-04-21 15:35:08.131654
run  tomcat crochet-callback 1 - 2018-04-21 15:35:20.838379
run  tomcat crochet 0 - 2018-04-21 15:35:32.784708
run  tomcat crochet 1 - 2018-04-21 15:35:43.455865
run  tomcat native 0 - 2018-04-21 15:35:53.880987
run  tomcat native 1 - 2018-04-21 15:35:59.293353
run  xalan crochet-callback 0 - 2018-04-21 15:36:04.558041
run  xalan crochet-callback 1 - 2018-04-21 15:36:09.886822
run  xalan crochet 0 - 2018-04-21 15:36:14.959994
run  xalan crochet 1 - 2018-04-21 15:36:19.134873
run  xalan native 0 - 2018-04-21 15:36:24.306002
run  xalan native 1 - 2018-04-21 15:36:26.204972
run  eclipse crochet-callback 0 - 2018-04-21 15:36:27.709454
run  eclipse crochet-callback 1 - 2018-04-21 15:36:37.801094
run  eclipse crochet 0 - 2018-04-21 15:36:47.278670
run  eclipse crochet 1 - 2018-04-21 15:36:55.780299
run  eclipse native 0 - 2018-04-21 15:37:03.103212
run  eclipse native 1 - 2018-04-21 15:37:07.027437
run  batik crochet-callback 0 - 2018-04-21 15:37:10.813552
run  batik crochet-callback 1 - 2018-04-21 15:37:15.793239
run  batik crochet 0 - 2018-04-21 15:37:22.031844
run  batik crochet 1 - 2018-04-21 15:37:27.781765
run  batik native 0 - 2018-04-21 15:37:33.936860
run  batik native 1 - 2018-04-21 15:37:35.616666
run  tradebeans crochet-callback 0 - 2018-04-21 15:37:37.196332
run  tradebeans crochet-callback 1 - 2018-04-21 15:38:12.724596
run  tradebeans crochet 0 - 2018-04-21 15:38:44.420048
run  tradebeans crochet 1 - 2018-04-21 15:39:12.437559
run  tradebeans native 0 - 2018-04-21 15:39:43.925629
run  tradebeans native 1 - 2018-04-21 15:40:08.503967
run  tradesoap crochet-callback 0 - 2018-04-21 15:40:44.629893
run  tradesoap crochet-callback 1 - 2018-04-21 15:41:39.121657
run  tradesoap crochet 0 - 2018-04-21 15:42:25.578833
run  tradesoap crochet 1 - 2018-04-21 15:43:07.036773
run  tradesoap native 0 - 2018-04-21 15:43:45.552659
run  tradesoap native 1 - 2018-04-21 15:44:08.327795
run  sunflow crochet-callback 0 - 2018-04-21 15:44:49.764407
run  sunflow crochet-callback 1 - 2018-04-21 15:44:54.518710
run  sunflow crochet 0 - 2018-04-21 15:44:58.131918
run  sunflow crochet 1 - 2018-04-21 15:45:01.759463
run  sunflow native 0 - 2018-04-21 15:45:04.668634
run  sunflow native 1 - 2018-04-21 15:45:05.468218
\end{verbatim}

    \item[stmbench7] Run command
        \command{/vagrant/experiments/stmbench7/run-quick.py}.  This runs an
        experiment for each cell of Table 3 twice.  Running this set of
        experiments took around 2 minutes on the user machine.

        Once the experiment finishes, you can check that there are no errors
        ensuring that command \command{grep -Ri exception /vagrant/results/stmbench7}
        does not print anything.

Sample output:
\begin{verbatim}
$ /vagrant/experiments/stmbench7/run-quick.py
run  rw-no-traversals deuce-tl2-notx 0 - 2018-04-21 15:51:43.285136
run  rw-no-traversals deuce-tl2-notx 1 - 2018-04-21 15:51:49.020830
run  rw-no-traversals deuce-tl2-checkpoint 0 - 2018-04-21 15:51:54.754906
run  rw-no-traversals deuce-tl2-checkpoint 1 - 2018-04-21 15:51:59.947000
run  rw-no-traversals crochet-nolock 0 - 2018-04-21 15:52:05.036420
run  rw-no-traversals crochet-nolock 1 - 2018-04-21 15:52:12.351039
run  rw-no-traversals deuce-lsa 0 - 2018-04-21 15:52:20.328280
run  rw-no-traversals deuce-lsa 1 - 2018-04-21 15:52:25.939218
run  rw-no-traversals jvstm-notx 0 - 2018-04-21 15:52:30.241208
run  rw-no-traversals jvstm-notx 1 - 2018-04-21 15:52:39.549989
run  rw-no-traversals jvstm-checkpoint 0 - 2018-04-21 15:52:48.165839
run  rw-no-traversals jvstm-checkpoint 1 - 2018-04-21 15:52:58.028558
run  rw-no-traversals deuce-lsa-checkpoint 0 - 2018-04-21 15:53:08.344633
run  rw-no-traversals deuce-lsa-checkpoint 1 - 2018-04-21 15:53:13.690544
run  rw-no-traversals deuce-tl2 0 - 2018-04-21 15:53:19.180774
run  rw-no-traversals deuce-tl2 1 - 2018-04-21 15:53:24.683599
run  rw-no-traversals native-nolock-jdk7 0 - 2018-04-21 15:53:29.880823
run  rw-no-traversals native-nolock-jdk7 1 - 2018-04-21 15:53:34.931993
run  rw-no-traversals jvstm 0 - 2018-04-21 15:53:41.258039
run  rw-no-traversals jvstm 1 - 2018-04-21 15:53:53.462001
run  rw-no-traversals deuce-lsa-notx 0 - 2018-04-21 15:54:03.639673
run  rw-no-traversals deuce-lsa-notx 1 - 2018-04-21 15:54:08.284661
run  rw-no-traversals crochet-nolock-checkpoint 0 - 2018-04-21 15:54:13.674983
run  rw-no-traversals crochet-nolock-checkpoint 1 - 2018-04-21 15:54:23.145096
run  rw-no-traversals native-nolock-jdk8 0 - 2018-04-21 15:54:32.034221
run  rw-no-traversals native-nolock-jdk8 1 - 2018-04-21 15:54:37.989324
\end{verbatim}

    \item[ftp] Run command
        \command{/vagrant/experiments/ftp/run-quick.py}.  This runs an
        experiment for each cell of Table 5 twice.  Running this set of
        experiments took around 2 minutes on the user machine.

        Once the experiment finishes, you can check that there are no errors
        ensuring that command \command{grep -Ri exception /vagrant/results/ftp}
        does not print anything.
        
        Sample output:
        \begin{verbatim}
$ /vagrant/experiments/ftp/run-quick.py
run  quick crochet-baseline 0 - 2018-04-21 15:55:32.939574
run  quick crochet-baseline 1 - 2018-04-21 15:55:55.178914
run  quick crochet 0 - 2018-04-21 15:56:09.519827
run  quick crochet 1 - 2018-04-21 15:56:18.132656
run  quick restart 0 - 2018-04-21 15:56:26.251934
run  quick restart 1 - 2018-04-21 15:56:34.221001
run  quick native 0 - 2018-04-21 15:56:42.533259
run  quick native 1 - 2018-04-21 15:56:55.955284
        \end{verbatim}

    \item[dacapo-h2] Run command
        \command{/vagrant/experiments/dacapo-h2/run-quick.py}.  This runs the
        experiment describe in Section~6.2 twice.  Running this set of
        experiments took around 3 minutes on the user machine.

        Once the experiment finishes, you can check that there are no errors
        ensuring that command \command{grep -R FAIL /vagrant/results/dacapo-h2}
        does not print anything.

Sample output:
\begin{verbatim}
$ /vagrant/experiments/dacapo-h2/run-quick.py
run  default native-sql 0 - 2018-04-21 15:57:47.207985
run  default native-sql 1 - 2018-04-21 15:57:51.790658
run  default crochet-sql 0 - 2018-04-21 15:57:56.684953
run  default crochet-sql 1 - 2018-04-21 15:58:05.240117
run  default crochet 0 - 2018-04-21 15:58:12.131372
run  default crochet 1 - 2018-04-21 15:58:21.772960
\end{verbatim}
\end{description}

\subsubsection{XJ VM}

\begin{description}

    \item[xj] Run command \command{/vagrant/experiments/xj/run-quick.py}.  This
        runs an experiment for each cell of Table 4 twice.  Running this set of
        experiments took around 3 minutes on the user machine.

        Once the experiment finishes, you can check that there are no errors
        ensuring that commands \command{grep -Ri exception \$HOME/results/xj} and
        \command{grep -Ri differ \$HOME/results/xj} do not print anything.

Sample output:
\begin{verbatim}
$ /vagrant/experiments/xj/run-quick.py
run  default native-seqhashset 0 - 2018-04-21 16:25:26.026903
run  default native-seqhashset 1 - 2018-04-21 16:25:26.113166
run  default xj-closedhashset 0 - 2018-04-21 16:25:26.217164
run  default xj-closedhashset 1 - 2018-04-21 16:25:26.226836
run  default native-closedhashset 0 - 2018-04-21 16:25:26.235858
run  default native-closedhashset 1 - 2018-04-21 16:25:26.341823
run  default crochet-seqhashset 0 - 2018-04-21 16:25:26.459114
run  default crochet-seqhashset 1 - 2018-04-21 16:25:27.511073
run  default crochet-closedhashset 0 - 2018-04-21 16:25:28.524277
run  default crochet-closedhashset 1 - 2018-04-21 16:25:29.476202
\end{verbatim}

\end{description}

\subsection{Paper run}
\label{sec:paper-run}

Running the full set of results used for the paper is similar to running the
quick results, described above.  The difference is that you will use scripts
\texttt{run.py} instead of \texttt{run-quick.py} for each experiment.

In the following, we provide the time to run each experiment on the
test machine with the Main VM extracted, as described in
Section~\ref{sec:extract}.  We ran the \emph{xj} experiment inside the XJ VM.

You can cut down the number of repetitions of each benchmark in order to reduce the time needed to run them. However, if you run less than 10 iterations it's unlikely that there will be sufficient samples to generate confidence intervals as presented in the paper. If you want to try this, set variable \texttt{GLOBAL\_TIMES} to
        10 in file \command{/vagrant/scripts/paths.sh}, reset the environment with
        command \command{source /vagrant/scripts/paths.sh} 

\begin{description}

    \item[microbenchmark] Around 25h

    \item[dacapo] Around 8h.  Depending on your setup, benchmark \texttt{h2} may
        fail to converge.  When this happens, instead of it reporting a result,
        it prints the following error:~\emph{Benchmark failed to converge}.
        Extracting the artifact from the VM and pinning the benchmark to
        specific cores, as described in Section~\ref{sec:extract}, should fix
        this problem. Note: `lusearch' may non-deterministically throw exceptions in \emph{all} configurations (e.g. not just with \sysname) in particularly resource constrained environments, like a VM with a single CPU and very little RAM. We have configured the VM to be allocated 4 CPUs and 8GB of RAM, which seems to allow it to pass consistently inside of the VM. 

    \item[stmbench7] \XXX

    \item[ftp] \XXX

    \item[xj] Around 1h

\end{description}

\section{Generate result tables}
\label{sec:tables}

The directory containing the scripts to run each experiment --- \texttt{run.py}
and \texttt{run-quick.py} --- also contain scripts to generate the results
tables found in Section 5 and 6.  The name of these scripts start with
\texttt{table}.  For instance, to generate the tables for experiment
\texttt{dacapo} run command\linebreak
\command{/vagrant/experiments/dacapo/table-dacapo.py}.

Each table script reads the results from the environment variable set up by
\vm{/vagrant/scripts/paths.sh} / \host{scripts/paths.sh}, processes them, and
generates tables in CSV format in folder \vm{/vagrant/tables} / \host{tables}.

We generated the tables on the paper manually from the CSV files, importing them
first to spreadsheet software to help us in this task.  We recommend you do the
same to visualize the results more easily. These CSV files contain averages (`avg.') and confidence intervals for those averages (ranging from `ci0.' - `ci1.'). Each column in the CSV file has as a prefix the measurement (average value or confidence interval lower or upper bound) and as a suffix the configuration (normal for native, crij for \sysname, crijcb for \sysname with checkpoint, criu for CRIU).

\textbf{Our script will only generate confidence intervals if there are at least 10 valid observations from that benchmark.} This means that if you run a benchmark 10 times, and it fails to converge to a stable execution time several times, the generated table will not have confidence intervals for that benchmark. We had no difficulties ensuring that the benchmarks always converged to a stable time when we ran them \emph{outside} of the VM, \emph{and} when we pinned them to the same physical CPU cores. However, running them inside of the VM may result in too much noise for them to converge.

For the microbenchmarks table (Table 1):
\XXX

For the DaCapo table (Table 2): The columns

For the STM table (Table 3)

For the XJ table (Table 4): In the XJ VM, you'll find the result in \vm{~/tables} by default, after running \command{/vagrant/experiments/xj/table-xj.sh}. The ``native'' row in the CSV output corresponds to the SequentialHashIntSet row in Table 5, and the ``xj'' row in the CSV output corresponds to the ClosedHashIntSet row in Table 5. The next three columns provide the average and confidence interval for the number of operations performed on the baseline JVM; the next three provide the average and confidence interval for the \% of those operations performed by \sysname, and the final three columns provide the average and confidence interval for the \% of those operations performed by XJ.
For the FTP table (Table 5)
\section{Algorithm location}
\label{sec:algorithm}

When reviewing the algorithm presented in Listings 1 and 2, please note that there were several typos identified by us and the reviewers in the originally submitted version of \sysname. As of this writing, we are continuing to clarify the paper (in particular the argument for the thread safety of \sysname, which we agree is not presented as clearly as it could be). However, we have included with this artifact a revised version of the submitted paper with some of the errors corrected. Please use the included version of the paper for reference.

The code that implements the pseudo-code in Section~\XXX can be found in folder
\vm{\$HOME/software/crochet/TODO}.  As explained in the paper, each class
has two states:  \texttt{SLOW} or \texttt{FAST}.  The code for checkpoint,
rollback, and read/write for each state can be found in methods \XXX,
respectively.

\section{Run the artifact outside of the VM}
\label{sec:extract}
\label{sec:last}

The XJ VM is not possible to run outside of its VM because the version of
OpenJDK does not build successfully on modern systems.  We were able to build a
version of XJ by working around the compiler errors, only to have it allocate
all the memory available when code JIT compiling is on and eventually crash.

We followed the following approach to execute the experiments provided by the
Main VM directly on our test machine, which we provide for the benefit of interested reviewers:

\begin{enumerate}

    \item In file \host{scripts/paths.sh}, configure all the build and install
        directories to reflect where you are building the artifact on your
        machine.

    \item Source file \host{scripts/paths.sh} so set up the environment.  Note
        that you will need to source this file after each time you modify it.

    \item The provisioning entry-point can be found at the end of file
        \host{Vagrantfile}.  Follow those steps until you reach the invocation
        of script \texttt{build-all.sh}. The provisioning uses \texttt{apt-get}
        as the package manager, you need to change this to the package manager
        your distribution uses to install the same packages.

    \item Follow each build script in folder \host{scripts/build} by the same
        order in which script \host{scripts/build-all.sh} calls them.  Modify
        the package manager commands and ensure all other commands work.  We
        advice going one file at the time, instead of blindly executing
        \host{scripts/build-all.sh} to build everything in one go.

    \item Adapt and execute all the commands in file
        \host{scripts/pre-run.sh}.

\end{enumerate}

By now, you should have the artifact deployed directly on your machine.  In each
experiment script \texttt{run.py}, there is a variable \texttt{wrap} that
defines a command to wrap the execution of each experiment.  This is a good
place to place commands to pin process to particular CPUs (e.g.,
\texttt{taskset} or \texttt{numactl}).

Pinning the experiments on cores on the same CPU ensures good quality results,
with low noise.  We strongly recommend doing so, especially for NUMA machines.

\section{Going beyond the benchmarks}
To run \sysname with an arbitrary java program, you'll need to use the instrumented JVM, and then specify \sysname's java agent, JVMTI agent, and boot classpath addon. In the VM, the appropriate syntax would be:
\begin{verbatim}
/home/ubuntu/software/crochet/target/jre-inst/bin/java \
-Xmx4G -agentpath:/home/ubuntu/software/crochet/target/libtagging.so\
-javaagent:/home/ubuntu/software/crochet/target/CRIJ-0.0.1-SNAPSHOT.jar\
-Xbootclasspath/p:/home/ubuntu/software/crochet/target/CRIJ-0.0.1-SNAPSHOT.jar\
 ...rest of your java command.	
\end{verbatim}
 
 
 Perhaps the easiest way to experiment with \sysname is using the integrated test suite and test suite runner. \sysname is a maven project, and is configured to run validation tests when you invoke \command{mvn verify}. You can inspect the test cases and add new ones (just make sure that the test class names end with \texttt{ITCase}. You can then use the \texttt{CheckpointRollbackAgent} API to checkpoint or rollback objects. The easiest way is to (as most of the test cases do) first generate a new and valid version number to use (e.g. \texttt{		int v = getNewVersionForCheckpoint();}) and then simply call \texttt{checkpoint} or \texttt{rollback} on objects that you are interested in testing on. For instance, the test \texttt{ArrayCheckpointRollbackITCase\#testPrimitiveArray} tests the correct handling of primitive arrays in \sysname (which require special handling compared to other objects).
 
The expected output of running \command{mvn verify} is (only including test results for brevity):
\begin{scriptsize}
\begin{verbatim}
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running net.jonbell.crij.test.LinkedListITCase
Testing list of size three, no nesting:  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
Testing list of size three, nesting one:  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
Testing list of size three, nesting two:  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
Testing list of size four, no nesting:  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49
Testing list of size four, nesting one:  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49
Testing list of size four, nesting two:  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49
Testing list of size one, no nesting:  0 1 2 3 4 5
Testing list of size one, nesting one:  0 1 2 3 4 5
Testing list of size one, nesting two:  0 1 2 3 4 5
Testing list of size two, no nesting:  0 1 2 3 4 5 6 7 8 9
Testing list of size two, nesting one:  0 1 2 3 4 5 6 7 8 9
Testing list of size two, nesting two:  0 1 2 3 4 5 6 7 8 9
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.362 sec - in net.jonbell.crij.test.LinkedListITCase
Running net.jonbell.crij.test.CheckpointRollbackITCase
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.2 sec - in net.jonbell.crij.test.CheckpointRollbackITCase
CP found testRBInSameMethod()V
CP found testRBInOtherMethod()V
CP found doStaticTest()V
CP found testRBInOtherStaticMethod()V
CP found foos()V
CP found foo()V
Running net.jonbell.crij.test.SimpleStackModeAutoCPITCase
Version: 4
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.974 sec - in net.jonbell.crij.test.SimpleStackModeAutoCPITCase
Running net.jonbell.crij.test.ClassLoaderITCase
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.104 sec - in net.jonbell.crij.test.ClassLoaderITCase
Running net.jonbell.crij.test.ReflectionITCase
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.397 sec - in net.jonbell.crij.test.ReflectionITCase
Running net.jonbell.crij.test.TaggingITCase
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.304 sec - in net.jonbell.crij.test.TaggingITCase
Running net.jonbell.crij.test.SimpleStackModeITCase
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.773 sec - in net.jonbell.crij.test.SimpleStackModeITCase
Running net.jonbell.crij.test.AliasingITCase
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.05 sec - in net.jonbell.crij.test.AliasingITCase
Running net.jonbell.crij.test.FlatNestingITCase
Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.289 sec - in net.jonbell.crij.test.FlatNestingITCase
Running net.jonbell.crij.test.StartCheckpointITCase
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.335 sec - in net.jonbell.crij.test.StartCheckpointITCase
Running net.jonbell.crij.test.AliasingStressITCase
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.422 sec - in net.jonbell.crij.test.AliasingStressITCase
Running net.jonbell.crij.test.ArrayCheckpointRollbackITCase
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.61 sec - in net.jonbell.crij.test.ArrayCheckpointRollbackITCase
Running net.jonbell.crij.test.ObjectFieldITCase
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.764 sec - in net.jonbell.crij.test.ObjectFieldITCase

Results :

Tests run: 40, Failures: 0, Errors: 0, Skipped: 4
\end{verbatim}
\end{scriptsize}
\end{document}

