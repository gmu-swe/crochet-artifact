\title{CROCHET Artifact Guide}
\author{Jonhattan Bell \and Lu\'{i}s Pina}
\date{\today}

\documentclass[12pt]{article}

\renewcommand\thesection{\Alph{section}}

\usepackage{url}
\usepackage{hyperref}

\begin{document}
\maketitle

\begin{abstract}
This is the paper's abstract \ldots
\end{abstract}

\section{Introduction}

The sections on this paper are \emph{named} A through XXX to avoid any confusion with
the sections on the paper, which are \emph{numbered} 1 through XXX.

\subsection{Structure of this artifact}

This artifact consists of two VMs which are set-up and provisioned using
Vagrant.\footnote{\url{https://www.vagrantup.com/}}  You should install Vagrant
and Virtualbox in your system.

We tested this artifact with Vagrant version XXX and Virtualbox version XXX on
GNU/Linux and Vagrant version YYY and Virtualbox version YYY on MacOS.

\subsubsection{Main VM}
\label{sec:main}

The first VM is the Main VM that runs all the experiments except Section~XXX on
the paper.  It uses Ubuntu 16.04 LTS as the underlying operating system, and you
can find it on directory XXX.  It's structure is as follows:

\begin{description}

    \item[Vagrantfile] File that describes how Vagrant should provision the VM.
        Parameter \texttt{config.vm.provision}, at the end of the file,
        describes how to provision the artifact VM by running shell scripts
        listed below on this document.  Please customize the following
        parameters:

        \begin{description}

            \item[vm.memory] Memory that the VM will have.  We recommend at least 8G (8192MB).

            \item[vm.cpus] Number of CPUs available to the VM.  We recomment at least 2, more is better.

        \end{description}

    \item[downloads] The artifact requires some files to be downloaded from the
        internet and saved here.  We already populated this directory for your
        convenience.  File \texttt{scripts/downloads.sh} should be able to
        re-download them if needed.

        \begin{itemize}

            \item Oracle HotSpot JDK7

            \item Oracle HotSpot JDK8

            \item DaCapo 9.12 jar file

        \end{itemize}

    \item[scripts]  Several scripts and utilities used throughout the VM.  File
        \texttt{scripts/path.sh} is of particular interest as it sets the
        environment used throughout the artifact.  Ensure that variable
        \texttt{GLOBAL\_JVM\_PARAMS} configures JVMs with a maximum heap size
        that fits in the memory you configured the artifact VM with, in file
        \texttt{Vagrantfile} with parameter \texttt{vb.memory}.  We recommend at
        least 4GB with: \texttt{GLOBAL\_JVM\_PARAMS="-Xmx4G"}

    \item[experiments]  Each experiment reported in the paper has a
        subdirectory with the scripts to run it and generate a table with its
        results:

        \begin{description}

            \item[microbenchmarks] Section~5.1

            \item[dacapo] Section~5.2

            \item[stmbench7] Section~5.3, Table~3

            \item[ftp] Section~6.1

            \item[dacapo-h2] Section~6.2

        \end{description}

    \item[results]  The artifact saves the raw results of each experiment in
        this directory, under a subdirectory structure similar to the
        experiments structure.

        Note that Vagrant synchronizes the contents of this folder on the host
        machine with the contents of folder \texttt{/vagrant} on the VM.
        This means that writes from the host are visible inside the VM, and
        vice-versa.  Putting the results here ensures that you can access them
        from the host without needint to start the VM.

    \item[tables]  Similarly to the results, the artifact saves in this
        directory the tables generated from the raw results.

\end{description}

\subsubsection{XJ VM}

The second VM only runs the experiments for Table~4 in Section~5.2 of the paper.

The structure of the VM is very similar to the Main VM, described in
Section~\ref{sec:main}.

\begin{description}

    \item[Vagrantfile] Similar file to the Main VM, please configure it as you
        did above.

    \item[downloads] The XJ VM requires the sources of the XJ JVM and the
        experiments it uses.  These files were kindly made available by the
        authors of XJ, and are saved here.

        \begin{itemize}

            \item openjdk.zip

            \item xj.zip

        \end{itemize}

    \item[scripts]  Same as above, please configure it in a similar way.

    \item[experiments]  Only one experiment in this VM:

        \begin{description}

            \item[xj] Section~5.3, Table~4

        \end{description}

    \item[results]  Note that the XJ VM does not synchronize this folder with
        folder \texttt{/vagrant} inside the VM, as before.  Instead, on startup,
        it overwrites folder \texttt{/vagrant} in the VM with the contents of
        this file.

        For the results not to be lost between VM cycling, the results can now
        be found in folder \texttt{\$HOME/results} inside the VM.
        Unfortunately, you have to copy them manually to the host machine (e.g.,
        by using \texttt{scp}).


    \item[tables]  Moved to folder \texttt{\$HOME/tables} for the same reason as
        the results.

\end{description}


\section{Provision the VM}

This section explains how to provision each VM.

Jon, create directory \texttt{repos} and run command
\texttt{../scripts/populateRepos.sh} from it to clone all the private repos
needed for the artifact. (delete this before sending the final version of this
guide)

\subsection{Main VM}

Once you have configure file \texttt{Vagrantfile} and have all required
downloaded files, as described in Section~\ref{sec:main}, simply run the command
\texttt{vagrant up} from the directory XXX.  Provisioning the Main VM took around 10
minutes on a machine equipped with XXX.

\subsection{XJ VM}

Provisioning the Main VM took around 24 minutes on a machine equipped with XXX.

\section{Run the experiments}

To log-on a provisioned VM, use command \texttt{vagrant ssh}.  If a provisioned
machine is not running (either is stopped or suspended), you can start it with
command \texttt{vagrant up}.  To stop a running VM, log-on and type \texttt{sudo
poweroff}.  To suspend a running vm, use command \texttt{vagrant suspend}.

To run each experiment, you should log-on to the machine and type command
\texttt{source /vagrant/scripts/paths.sh} to set up the environment correctly.

Please note that folder \texttt{/vagrant} is the same folder where you typed
\texttt{vagrant up} on the host machine, and any changes between these folders
are synchronized.  Some experiments (e.g., DaCapo) write scratch results on the
directory in which they are launched from.  Therefore, to avoid directory
synchronization overhead, we recommend running the experiments from folder
\texttt{/home/ubuntu} on the Main VM, and folder XXX on the XJ VM.

To stop a running experiment, interrupting the experiment script with
\texttt{CTRL+C} is not enough, as the current iteration will continue to execute
in the background.  You can stop it with command \texttt{killall -KILL java}.

All experiments run on the Main VM, except for experiments reported in Table~4.

\subsection{Quick run}

Quick runs are smaller versions of the regular experiment, ideal for the
\emph{kick-the-tires} phase of testing.  If these experiments complete
successfully, then the regular experiments should also do so.  In the following,
we describe how to run each quick experiment.

Note that quick experiments write their results in the same directory of the
regular experiments.  This is so that you can also test the scripts that
generate the tables from the data.  However, running a quick experiment will
overwrite any data left from the regular experiment.

\subsubsection{Main VM}

\begin{description}

    \item[microbenchmarks] Run command
        \texttt{/vagrant/experiments/micro/run-quick.py}.  This runs an
        experiment for each cell of Table 1 twice.  Running this set of
        experiments took around 30 minutes on a machine XXX.

        Once the experiment finishes, you can check that there are no errors
        ensuring that command \texttt{grep -Ri exception /vagrant/results/microbenchmark}
        does not print anything.

        Note that this quick run does not generate the full results, so the
        table generating scripts described in Section~\ref{sec:tables} will not
        work.  If you want to try those, set variable \texttt{GLOBAL\_TIMES} to
        2 in file \texttt{/vagrant/scripts/paths.sh}, reset the environment with
        command \texttt{source /vagrant/scripts/paths.sh} and do a paper run,
        described in Section~\ref{sec:paper-run}.

    \item[dacapo] Run command \texttt{/vagrant/experiments/dacapo/run-quick.py}.
        This runs an experiment for each cell of Table 2 twice.  Running this
        set of experiments took around 5 minutes on a machine XXX.

        Once the experiment finishes, you can check that there are no errors
        ensuring that command \texttt{grep -R FAIL /vagrant/results/dacapo} does not
        print anything.  Note that benchmark \texttt{tradesoap} may fail
        non-deterministically even for the native case, and is not included on
        the main results on Table XXX; please ignore errors from this benchmark.

    \item[stmbench7] Run command
        \texttt{/vagrant/experiments/stmbench7/run-quick.py}.  This runs an
        experiment for each cell of Table 3 twice.  Running this set of
        experiments took around 2 minutes on a machine XXX.

        Once the experiment finishes, you can check that there are no errors
        ensuring that command \texttt{grep -Ri exception /vagrant/results/stmbench7}
        does not print anything.

    \item[ftp] Run command
        \texttt{/vagrant/experiments/ftp/run-quick.py}.  This runs an
        experiment for each cell of Table 5 twice.  Running this set of
        experiments took around 2 minutes on a machine XXX.

        Once the experiment finishes, you can check that there are no errors
        ensuring that command \texttt{grep -Ri exception /vagrant/results/ftp}
        does not print anything.

    \item[dacapo-h2] Run command
        \texttt{/vagrant/experiments/dacapo-h2/run-quick.py}.  This runs the
        experiment describe in Section~6.2 twice.  Running this set of
        experiments took around 3 minutes on a machine XXX.

        Once the experiment finishes, you can check that there are no errors
        ensuring that command \texttt{grep -R FAIL /vagrant/results/dacapo-h2}
        does not print anything.

\end{description}

\subsubsection{XJ VM}

\subsection{Paper run}
\label{sec:paper-run}

Don't forget about \emph{Benchmark failed to converge} for dacapo or dacapo-h2.

\begin{description}

    \item[dacapo] Around 8h

\end{description}

\section{Generate result tables}
\label{sec:tables}

\section{Run the artifact outside of the VM}

The XJ VM is not possible to run outside of its VM because the version of
OpenJDK does not build successfully on modern systems.  We were able to build a
version of XJ by working around the compiler errors, only to have it allocate
all the memory available when code JIT compiling is on.

We followed the following approach to execute the experiments provided by the
Main VM directly on our test machine:

\begin{enumerate}

    \item In file \texttt{scripts/paths.sh}, configure all the build and install
        directories to reflect where you are building the artifact on your
        machine.

    \item Source file \texttt{scripts/paths.sh} so set up the environment.  Note
        that you will need to source this file after each time you modify it.

    \item The provisioning entry-point can be found at the end of file
        \texttt{Vagrantfile}.  Follow those steps until you reach the invocation
        of script \texttt{build-all.sh}. The provisioning uses \texttt{apt-get}
        as the package manager, you need to change this to the package manager
        your distribution uses to install the same packages.

    \item Follow each build script in folder \texttt{scripts/build} by the same
        order in which script \texttt{scripts/build-all.sh} calls them.  Modify
        the package manager commands and ensure all other commands work.  We
        advice going one file at the time, instead of blindly executing
        \texttt{scripts/build-all.sh} to build everything in one go.

    \item Adapt and execute all the commands in file
        \texttt{scripts/pre-run.sh}.

\end{enumerate}

By now, you should have the artifact deployed directly on your machine.  In each
experiment script \texttt{run.py}, there is a variable \texttt{wrap} that
defines a command to wrap the execution of each experiment.  This is a good
place to place commands to pin process to particular CPUs (e.g.,
\texttt{taskset} or \texttt{numactl}).

Pinning the experiments on cores on the same CPU ensures good quality results,
with low noise.  We strongly recommend doing so, especially for NUMA machines.

\end{document}
